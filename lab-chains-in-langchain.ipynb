{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Lab | Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541eb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84e441b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a09c35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\r\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Product  \\\n",
       "0       Queen Size Sheet Set   \n",
       "1     Waterproof Phone Pouch   \n",
       "2        Luxury Air Mattress   \n",
       "3             Pillows Insert   \n",
       "4  Milk Frother Handheld\\r\\n   \n",
       "\n",
       "                                              Review  \n",
       "0  I ordered a king size set. My only criticism w...  \n",
       "1  I loved the waterproof sac, although the openi...  \n",
       "2  This mattress had a small hole in the top of i...  \n",
       "3  This is the best throw pillow fillers on Amazo...  \n",
       "4  Â I loved this product. But they only seem to l...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427e1119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e92dff22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install the required package\n",
    "# %pip install langchain openai\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "943237a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace None by your own value and justify\n",
    "llm = ChatOpenAI(temperature=0.7, model=\"gpt-4o-mini\", openai_api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdcdb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template( #Write a query that would take a variable to describe any product\n",
    " \"\"\"\n",
    "    Describe the product {product} in a few sentences.\n",
    "    The description should be in a professional tone and should include the product's main features and benefits.\n",
    " \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7abc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (prompt | llm) #Create a chain that takes the prompt and the LLM as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad44d1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The Apple iPhone 14 Pro Max is a flagship smartphone that seamlessly combines cutting-edge technology with elegant design. It features a stunning 6.7-inch Super Retina XDR display, offering vibrant colors and exceptional clarity, making it ideal for both media consumption and productivity. Powered by the A16 Bionic chip, the device delivers unparalleled performance and efficiency, ensuring smooth multitasking and responsive gaming experiences. The advanced camera system, including a 48MP main sensor, allows for remarkable photography, even in low-light conditions, while ProRAW and ProRes video capabilities provide professionals with unmatched creative control. Additionally, the iPhone 14 Pro Max boasts enhanced battery life, 5G connectivity, and robust security features, making it a versatile choice for users seeking both sophistication and functionality in their mobile experience.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 45, 'total_tokens': 206, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_44added55e', 'finish_reason': 'stop', 'logprobs': None}, id='run-19ace788-ae70-4086-b2ca-c4852df217eb-0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Apple iPhone 14 Pro Max\"\n",
    "chain.invoke({\"product\": product}) #Invoke the chain with the product variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "febee243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22be3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9,model=\"gpt-4o-mini\", openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f31aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "        Describe the product {product} in a few sentences.\n",
    "        The description should be in a professional tone and should include the product's main features and benefits.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f5d5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    summarize the description of the product in a few sentences: {product_description} \n",
    "    \"\"\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c1eb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78458efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma0me\\AppData\\Local\\Temp\\ipykernel_22208\\228193363.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  overall_simple_chain.run(product)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mThe Apple iPhone 14 Pro Max is a premium smartphone that combines cutting-edge technology with sleek design. Featuring a stunning 6.7-inch Super Retina XDR display, it delivers vibrant colors and exceptional clarity for an immersive viewing experience. The device is powered by the A16 Bionic chip, ensuring lightning-fast performance and efficiency for demanding applications and multitasking. With a sophisticated camera system that includes a 48MP main lens, advanced low-light capabilities, and ProRAW and ProRes video recording, users can capture professional-quality photos and videos. Additionally, the iPhone 14 Pro Max supports 5G connectivity, providing ultra-fast download speeds and seamless streaming. With its durable design, enhanced battery life, and robust security features, the iPhone 14 Pro Max is engineered to meet the needs of the most discerning users.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe Apple iPhone 14 Pro Max is a high-end smartphone featuring a 6.7-inch Super Retina XDR display for vibrant visuals and clarity. It is powered by the A16 Bionic chip for fast performance and multitasking, and includes a sophisticated camera system with a 48MP main lens for professional-quality photography and videography. Supporting 5G connectivity for fast download speeds, the device also boasts a durable design, extended battery life, and advanced security features, making it ideal for discerning users.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Apple iPhone 14 Pro Max is a high-end smartphone featuring a 6.7-inch Super Retina XDR display for vibrant visuals and clarity. It is powered by the A16 Bionic chip for fast performance and multitasking, and includes a sophisticated camera system with a 48MP main lens for professional-quality photography and videography. Supporting 5G connectivity for fast download speeds, the device also boasts a durable design, extended battery life, and advanced security features, making it ideal for discerning users.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd59bda-9d02-44e7-b3d6-2bec61b99d8f",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51823099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mThe Google Pixel 9a is a cutting-edge smartphone designed to deliver an exceptional user experience through its combination of advanced technology and user-friendly functionality. Featuring a vibrant 6.1-inch OLED display, the Pixel 9a offers stunning visuals and rich colors, making it ideal for media consumption and everyday usage. Equipped with a powerful Google Tensor chip, it ensures smooth performance and efficient multitasking. The device boasts an impressive camera system, including advanced computational photography capabilities that allow users to capture stunning images in any lighting condition. Additionally, the Pixel 9a runs on the latest version of Android, providing seamless access to Google services and regular updates for enhanced security and performance. With its sleek design and robust features, the Google Pixel 9a stands out as a reliable choice for both productivity and entertainment.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe Google Pixel 9a is an advanced smartphone that offers a vibrant 6.1-inch OLED display for stunning visuals and rich colors, making it perfect for media consumption. Powered by the Google Tensor chip, it delivers smooth performance and efficient multitasking. Its impressive camera system features advanced computational photography capabilities, allowing users to take exceptional photos in various lighting conditions. Running on the latest Android version, it provides easy access to Google services and regular updates, making it a reliable option for both productivity and entertainment.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Google Pixel 9a is an advanced smartphone that offers a vibrant 6.1-inch OLED display for stunning visuals and rich colors, making it perfect for media consumption. Powered by the Google Tensor chip, it delivers smooth performance and efficient multitasking. Its impressive camera system features advanced computational photography capabilities, allowing users to take exceptional photos in various lighting conditions. Running on the latest Android version, it provides easy access to Google services and regular updates, making it a reliable option for both productivity and entertainment.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(\"Google Pixel 9a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c129ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "016187ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=\"gpt-4o-mini\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "  #This prompt should translate a review\n",
    "  \"\"\"\n",
    "    Write an English review of the product {product} in a few sentences.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt,\n",
    "                     output_key=\"firstPrompt\" #Give a name to your output\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0fb0730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    #Write a promplt to summarize a review\n",
    "    \"\"\"\n",
    "    summarize the review of the product in a few sentences: {firstPrompt}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"secondPrompt\" #give a name to this output\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6accf92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english or other language\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "   \"\"\"\n",
    "    Translate the review to Arabic: {secondPrompt}\\nMake sure to answer with the translation only. ONLY THE TRANSLATION.\n",
    "    \"\"\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"thirdPrompt\" #give a name to this output\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7a46121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message that take as inputs the two previous prompts' variables\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "       \"\"\"\n",
    "Using the outputs of the previous two prompts, craft a follow-up message. \n",
    "The first output is: {secondPrompt}\n",
    "The second output is: {thirdPrompt}\n",
    "       \"\"\"\n",
    ")\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"frouthPrompt\" #give a name to this output\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89603117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"product\"],\n",
    "    output_variables=[\"secondPrompt\", \"thirdPrompt\", \"frouthPrompt\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51b04f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'product': \"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\r\\nVieux lot ou contrefaÃ§on !?\",\n",
       " 'secondPrompt': \"The reviewer was disappointed with the product's quality, noting that the flavor was mediocre and lacked the expected richness. They found the mousse's consistency unsatisfactory and compared it unfavorably to similar items purchased elsewhere. Suspecting it might be an old batch or counterfeit, the reviewer ultimately does not recommend the product.\",\n",
       " 'thirdPrompt': 'ÙØ§Ù Ø§ÙÙØ±Ø§Ø¬Ø¹ ÙØ®ÙØ¨ÙØ§ ÙÙØ£ÙÙ Ø¨Ø¬ÙØ¯Ø© Ø§ÙÙÙØªØ¬Ø ÙØ´ÙØ±ÙØ§ Ø¥ÙÙ Ø£Ù Ø§ÙÙÙÙØ© ÙØ§ÙØª ÙØªÙØ³Ø·Ø© ÙÙÙØªÙØ± Ø¥ÙÙ Ø§ÙØºÙÙ Ø§ÙÙØªÙÙØ¹. ÙØ¬Ø¯ÙØ§ Ø£Ù ÙÙØ§Ù Ø§ÙÙÙØ³ ØºÙØ± ÙØ±Ø¶Ù ÙÙØ§Ø±ÙÙ Ø¨Ø³ÙØ¨ÙØ© ÙØ¹ Ø¹ÙØ§ØµØ± ÙÙØ§Ø«ÙØ© ØªÙ Ø´Ø±Ø§Ø¤ÙØ§ ÙÙ Ø£ÙØ§ÙÙ Ø£Ø®Ø±Ù. ÙØ´Ø¯Ø¯ÙØ§ Ø¹ÙÙ Ø£ÙÙ ÙØ¯ ÙÙÙÙ Ø¯ÙØ¹Ø© ÙØ¯ÙÙØ© Ø£Ù ÙØ²ÙÙØ©Ø ÙÙ Ø§ÙÙÙØ§ÙØ© ÙÙ ÙÙØµÙ Ø§ÙÙØ±Ø§Ø¬Ø¹ Ø¨Ø§ÙÙÙØªØ¬.',\n",
       " 'frouthPrompt': \"Subject: Follow-Up on Product Quality Concerns\\n\\nDear [Reviewerâs Name],\\n\\nThank you for sharing your feedback regarding your recent experience with our product. We sincerely apologize for the disappointment you encountered with the flavor and consistency of the mousse. Your observations about the richness not meeting expectations and the comparison to similar items are invaluable to us.\\n\\nWe take quality very seriously and are committed to ensuring that our products meet our customers' standards. We would love to investigate further regarding your concerns about the batch quality you received, as we certainly do not want our customers to feel as though they have received an inferior product.\\n\\nIf you could provide us with your purchase details, we would appreciate the opportunity to address these issues. Your satisfaction is our top priority, and we want to ensure that we can make this right for you.\\n\\nThank you once again for your input. We look forward to hearing from you.\\n\\nBest regards,\\n\\n[Your Name]  \\n[Your Position]  \\n[Your Company]  \\n[Contact Information]\"}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187cf07-458a-4226-bec7-3dec7ee47af2",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products or reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c38c473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'product': \"\\xa0I loved this product. But they only seem to last a few months. The company was great replacing the first one (the frother falls out of the handle and can't be fixed). The after 4 months my second one did the same. I only use the frother for coffee once a day. It's not overuse or abuse. I'm very disappointed and will look for another. As I understand they will only replace once. Anyway, if you have one good luck.\",\n",
       " 'secondPrompt': 'The reviewer initially loved the frother for its performance, but was disappointed to encounter a recurring issue where the frother detaches from the handle after just a few months of use. Despite positive customer service experiences with replacements, the second frother also failed after four months. Due to these durability concerns, the reviewer is now seeking a more reliable alternative.',\n",
       " 'thirdPrompt': 'Ø£Ø­Ø¨ Ø§ÙÙØ±Ø§Ø¬Ø¹ ÙÙ Ø§ÙØ¨Ø¯Ø§ÙØ© Ø¬ÙØ§Ø² Ø§ÙØ±ØºÙØ© ÙØ£Ø¯Ø§Ø¦ÙØ ÙÙÙÙ Ø´Ø¹Ø± Ø¨Ø®ÙØ¨Ø© Ø£ÙÙ Ø¹ÙØ¯ÙØ§ ÙØ§Ø¬Ù ÙØ´ÙÙØ© ÙØªÙØ±Ø±Ø© ØªØªÙØ«Ù ÙÙ Ø§ÙÙØµØ§Ù Ø¬ÙØ§Ø² Ø§ÙØ±ØºÙØ© Ø¹Ù Ø§ÙÙÙØ¨Ø¶ Ø¨Ø¹Ø¯ Ø¨Ø¶Ø¹ Ø£Ø´ÙØ± ÙÙ Ø§ÙØ§Ø³ØªØ®Ø¯Ø§Ù. Ø¹ÙÙ Ø§ÙØ±ØºÙ ÙÙ ØªØ¬Ø§Ø±Ø¨ Ø§ÙØ®Ø¯ÙØ© Ø§ÙØ¹ÙÙØ§Ø¡ Ø§ÙØ¥ÙØ¬Ø§Ø¨ÙØ© ÙØ¹ Ø§ÙØ§Ø³ØªØ¨Ø¯Ø§ÙØ§ØªØ Ø¥ÙØ§ Ø£Ù Ø¬ÙØ§Ø² Ø§ÙØ±ØºÙØ© Ø§ÙØ«Ø§ÙÙ Ø£ÙØ¶ÙØ§ ÙØ´Ù Ø¨Ø¹Ø¯ Ø£Ø±Ø¨Ø¹Ø© Ø£Ø´ÙØ±. Ø¨Ø³Ø¨Ø¨ ÙØ°Ù Ø§ÙÙØ®Ø§ÙÙ Ø§ÙÙØªØ¹ÙÙØ© Ø¨Ø§ÙÙØªØ§ÙØ©Ø ÙØ¨Ø­Ø« Ø§ÙÙØ±Ø§Ø¬Ø¹ Ø§ÙØ¢Ù Ø¹Ù Ø¨Ø¯ÙÙ Ø£ÙØ«Ø± ÙÙØ«ÙÙÙØ©.',\n",
       " 'frouthPrompt': \"Thank you for sharing your experience with the frother. Itâs clear that while the performance initially met your expectations, the recurring issue with the handle detachment is understandably frustrating. Itâs great to hear that customer service was responsive, but it's disappointing that the second unit also failed after such a short period. If you're looking for a more reliable alternative, I would be happy to suggest some models that have received positive feedback for their durability. Let me know if that would be helpful!\"}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[4]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81cb9f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'product': 'This is the best throw pillow fillers on Amazon. Iâve tried several others, and theyâre all cheap and flat no matter how much fluffing you do. Once you toss these in the dryer after you remove them from the vacuum sealed shipping material, they fluff up great',\n",
       " 'secondPrompt': \"The reviewer highly praises the throw pillow fillers purchased from Amazon, stating they are the best they've tried. Unlike previous fillers that remained flat, these fluff up beautifully after a quick dryer toss, providing excellent support and comfort. The reviewer recommends these fillers for anyone looking to enhance their throw pillows, noting that they make the pillows look full and inviting.\",\n",
       " 'thirdPrompt': 'Ø§ÙÙØ±Ø§Ø¬Ø¹ ÙÙØ¯Ø­ Ø¨Ø´Ø¯Ø© Ø­Ø´ÙØ§Øª Ø§ÙÙØ³Ø§Ø¦Ø¯ Ø§ÙØ±ÙÙ Ø§ÙØªÙ ØªÙ Ø´Ø±Ø§Ø¤ÙØ§ ÙÙ Ø£ÙØ§Ø²ÙÙØ ÙØ´ÙØ±ÙØ§ Ø¥ÙÙ Ø£ÙÙØ§ Ø§ÙØ£ÙØ¶Ù Ø§ÙØªÙ Ø¬Ø±Ø¨ÙØ§. Ø¹ÙÙ Ø¹ÙØ³ Ø§ÙØ­Ø´ÙØ§Øª Ø§ÙØ³Ø§Ø¨ÙØ© Ø§ÙØªÙ Ø¸ÙØª ÙØ³Ø·Ø­Ø©Ø ÙØ¥Ù ÙØ°Ù Ø§ÙØ­Ø´ÙØ§Øª ØªÙØªÙØ® Ø¨Ø´ÙÙ Ø¬ÙÙÙ Ø¨Ø¹Ø¯ Ø±ÙÙÙØ§ Ø³Ø±ÙØ¹ÙØ§ ÙÙ Ø§ÙÙØ¬ÙÙØ ÙÙØ§ ÙÙÙØ± Ø¯Ø¹ÙÙØ§ ÙØ±Ø§Ø­Ø© ÙÙØªØ§Ø²Ø©. ÙÙØµÙ Ø§ÙÙØ±Ø§Ø¬Ø¹ Ø¨ÙØ°Ù Ø§ÙØ­Ø´ÙØ§Øª ÙØ£Ù Ø´Ø®Øµ ÙØ¨Ø­Ø« Ø¹Ù ØªØ­Ø³ÙÙ ÙØ³Ø§Ø¦Ø¯ Ø§ÙØ±ÙÙ Ø§ÙØ®Ø§ØµØ© Ø¨ÙÙØ ÙØ´ÙØ±ÙØ§ Ø¥ÙÙ Ø£ÙÙØ§ ØªØ¬Ø¹Ù Ø§ÙÙØ³Ø§Ø¦Ø¯ ØªØ¨Ø¯Ù ÙÙØªÙØ¦Ø© ÙØ¬Ø°Ø§Ø¨Ø©.',\n",
       " 'frouthPrompt': \"Thank you for your insightful reviews of the throw pillow fillers! It's great to hear that they stand out from previous options by providing such wonderful support and comfort. Your recommendation really emphasizes how important it is to have plush, inviting throw pillows in our living spaces. Do you have any tips on how to best maintain the fluffiness of these fillers over time? Also, if you have any favorite pillow covers that pair well with these fillers, Iâd love to hear about those too!\"}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[3]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ade83f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "biology_template = \"\"\"You are an excellent biologist. \\\n",
    "You have a deep understanding of living organisms, \\\n",
    "from the molecular and cellular level to entire ecosystems. \\\n",
    "You are skilled at observing patterns in nature, analyzing biological data, \\\n",
    "and explaining complex processes like evolution, genetics, physiology, and ecology. \\\n",
    "You can clearly communicate how life functions and adapts, \\\n",
    "and you make connections between different biological concepts \\\n",
    "to answer challenging questions.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f590e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"biology\",\n",
    "        \"description\": \"Good for answering biology questions\",\n",
    "        \"prompt_template\": biology_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31b06fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3f50bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8eefec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f98018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11b2e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1387109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2fb7d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma0me\\AppData\\Local\\Temp\\ipykernel_22208\\3038952769.py:1: LangChainDeprecationWarning: Please see migration guide here for recommended implementation: https://python.langchain.com/docs/versions/migrating_chains/multi_prompt_chain/\n",
      "  chain = MultiPromptChain(router_chain=router_chain,\n"
     ]
    }
   ],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d86b2131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Black body radiation refers to the electromagnetic radiation emitted by an idealized object known as a \"black body,\" which absorbs all incident radiation, regardless of frequency or angle. A perfect black body is a theoretical concept that does not reflect or transmit any light, making it appear completely black at room temperature.\\n\\nWhen a black body is heated, it emits radiation in a characteristic spectrum that depends solely on its temperature. This emission can be described by Planck\\'s law, which shows that the intensity of radiation emitted at different wavelengths increases with temperature. As the temperature rises, the peak of the emitted spectrum shifts to shorter wavelengths, a phenomenon known as Wien\\'s displacement law.\\n\\nBlack body radiation played a crucial role in the development of quantum mechanics, particularly through Max Planck\\'s work in the early 20th century, which introduced the idea of quantized energy levels. This helped resolve the \"ultraviolet catastrophe\" predicted by classical physics, where it was thought that a black body would emit infinite energy at short wavelengths.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b717379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To break down the problem \\\\(2 + 2\\\\):\\n\\n1. Identify the numbers involved: We have the numbers 2 and 2.\\n2. Understand the operation: The operation is addition, which means we are combining the two numbers.\\n\\nNow, we can perform the addition:\\n\\n\\\\[\\n2 + 2 = 4\\n\\\\]\\n\\nSo, the answer to the question \\\\(2 + 2\\\\) is \\\\(4\\\\).'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29e5be01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "biology: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Every cell in our body contains DNA because DNA serves as the fundamental blueprint for life. Here are several key reasons why this is the case:\\n\\n1. **Genetic Information Storage**: DNA (deoxyribonucleic acid) contains the genetic instructions necessary for the development, functioning, growth, and reproduction of all living organisms. It encodes the information required to produce proteins, which perform a vast array of functions within the cell.\\n\\n2. **Cellular Function and Identity**: Each cell in our body has a specific role, whether it be a muscle cell, nerve cell, or skin cell. The DNA in each cell contains the complete set of instructions for the organism, but different cells express different genes. This selective gene expression allows cells to specialize and perform their unique functions while still retaining the complete genetic information.\\n\\n3. **Replication and Inheritance**: DNA is capable of self-replication, which is essential for cell division. When a cell divides, it must replicate its DNA so that each daughter cell receives an identical copy of the genetic material. This ensures that genetic information is passed on from one generation of cells to the next, maintaining the integrity of the organism's genetic code.\\n\\n4. **Adaptation and Evolution**: DNA is subject to mutations, which can lead to variations in traits. These variations can be beneficial, neutral, or harmful, and they contribute to the process of natural selection. Over time, this genetic diversity allows populations to adapt to changing environments, which is a fundamental aspect of evolution.\\n\\n5. **Regulation of Biological Processes**: DNA not only encodes proteins but also contains regulatory sequences that control when and how genes are expressed. This regulation is crucial for responding to environmental changes, developmental cues, and maintaining homeostasis within the organism.\\n\\nIn summary, DNA is essential for the structure, function, and regulation of cells, and it plays a critical role in heredity and evolution. The presence of DNA in every cell ensures that the organism can grow, develop, and adapt throughout its life.\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0c60b-7ae0-453e-9467-142d8dafee6e",
   "metadata": {},
   "source": [
    "**Repeat the above at least once for different inputs and chains executions - Be creative!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1511b485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "computer science: {'input': 'What is the content of RAM in a computer?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The content of RAM (Random Access Memory) in a computer consists of data and instructions that the CPU (Central Processing Unit) needs to access quickly while performing tasks. Hereâs a breakdown of what this content typically includes:\\n\\n1. **Operating System**: The core components of the operating system (OS) that are currently in use, allowing the CPU to manage hardware and software resources.\\n\\n2. **Application Data**: Data from applications that are currently running. This can include user data, temporary files, and any other information that the application needs to function.\\n\\n3. **Program Instructions**: The executable code of programs that are currently being executed. This includes the instructions that the CPU processes to perform tasks.\\n\\n4. **Cache Data**: Frequently accessed data that is stored in RAM to speed up processing times. This can include variables, arrays, and other data structures that are used by running applications.\\n\\n5. **Buffers**: Temporary storage areas that hold data while it is being transferred between two locations, such as between the CPU and a disk drive.\\n\\n6. **Stack and Heap Memory**: The stack is used for static memory allocation (e.g., function calls, local variables), while the heap is used for dynamic memory allocation (e.g., objects created at runtime).\\n\\n7. **User Sessions**: Information related to user sessions, such as open files, user preferences, and other session-specific data.\\n\\n### Summary\\nIn essence, RAM serves as a high-speed storage area that allows the CPU to quickly access the data and instructions it needs to perform tasks efficiently. The content of RAM is volatile, meaning it is lost when the computer is turned off.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is the contents of RAM in a computer?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50456852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
